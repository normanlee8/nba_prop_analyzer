import pandas as pd
import numpy as np
import logging
from pathlib import Path
from prop_analyzer import config as cfg
from prop_analyzer.data import loader

def load_master_data():
    """
    Loads the cleaned master files generated by ETL.
    Uses loader to aggregate separate season files.
    """
    try:
        # Use loader to get combined box scores
        box_scores = loader.load_box_scores()
        
        # Load DVP Stats if available
        dvp_path = cfg.DATA_DIR / "master_dvp_stats.csv"
        if dvp_path.exists():
            dvp_df = pd.read_csv(dvp_path)
        else:
            dvp_df = None
            logging.warning("master_dvp_stats.csv not found. Skipping DVP merge.")

        # Load Team Stats
        _, team_stats, _ = loader.load_static_data()

        return box_scores, dvp_df, team_stats
    except Exception as e:
        logging.error(f"Failed to load master data: {e}")
        return None, None, None

def normalize_position(pos):
    """
    Standardizes position for DVP lookup.
    """
    if not isinstance(pos, str): return 'PG' 
    p = pos.split('-')[0].upper().strip()
    if p == 'G': return 'SG'
    if p == 'F': return 'PF'
    if p not in ['PG', 'SG', 'SF', 'PF', 'C']: return 'PG'
    return p

def add_rolling_features(df):
    """
    Calculates historical features (SZN Avg, L5, Rest) for training.
    """
    logging.info("Calculating historical rolling features (this may take a moment)...")
    
    # Ensure correct sort order
    df = df.sort_values(by=['PLAYER_ID', 'GAME_DATE']).reset_index(drop=True)
    
    stats_to_roll = ['PTS', 'REB', 'AST', 'PRA', 'PR', 'PA', 'RA', 'FG3M', 'STL', 'BLK', 'TOV', 'FANTASY_PTS']
    for col in stats_to_roll:
        if col not in df.columns: df[col] = 0.0

    grouped = df.groupby('PLAYER_ID')

    # 1. Days Rest
    df['prev_date'] = grouped['GAME_DATE'].shift(1)
    df['Days Rest'] = (df['GAME_DATE'] - df['prev_date']).dt.days.fillna(7).clip(upper=7)
    df.drop(columns=['prev_date'], inplace=True)
    
    # 2. Rolling Stats
    for col in stats_to_roll:
        # SZN Avg (Expanding Mean)
        df[f'{col}_SZN_AVG'] = grouped[col].expanding().mean().shift(1).values
        
        # L5 Avg (Rolling 5)
        df[f'{col}_L5_AVG'] = grouped[col].rolling(window=5, min_periods=1).mean().shift(1).values
        
        # L3 Avg
        df[f'{col}_L3_AVG'] = grouped[col].rolling(window=3, min_periods=1).mean().shift(1).values
        
        # L10 Std Dev
        df[f'{col}_L10_STD'] = grouped[col].rolling(window=10, min_periods=3).std().shift(1).values
        
        # EWMA 
        df[f'{col}_L5_EWMA'] = grouped[col].ewm(alpha=0.15, adjust=False).mean().shift(1).values

    # 3. Advanced Stats Rolling
    if 'USG_PROXY' in df.columns:
        df['SZN_USG_PROXY'] = grouped['USG_PROXY'].expanding().mean().shift(1).values
        df['L5_USG_PROXY'] = grouped['USG_PROXY'].rolling(window=5).mean().shift(1).values
        
    if 'TS_PCT' in df.columns:
        df['SZN_TS_PCT'] = grouped['TS_PCT'].expanding().mean().shift(1).values
        df['L5_TS_PCT'] = grouped['TS_PCT'].rolling(window=5).mean().shift(1).values

    # 4. Game Count
    df['SZN Games'] = grouped.cumcount().values 
    
    df.fillna(0, inplace=True)
    return df

def create_training_dataset(output_path=None):
    logging.info("--- Building Master Training Dataset ---")
    
    bs_df, dvp_df, team_stats_df = load_master_data()
    if bs_df is None or bs_df.empty:
        logging.critical("No box scores available. Aborting dataset creation.")
        return

    # 1. Base Filtering
    req_cols = ['PLAYER_ID', 'GAME_DATE', 'PTS', 'MIN', 'TEAM_ABBREVIATION', 'OPPONENT_ABBREV']
    if not all(c in bs_df.columns for c in req_cols):
        logging.error(f"Box scores missing required columns: {req_cols}")
        return

    bs_df['GAME_DATE'] = pd.to_datetime(bs_df['GAME_DATE'])
    bs_df.sort_values(by=['PLAYER_ID', 'GAME_DATE'], inplace=True)

    # Rolling History
    try:
        bs_df = add_rolling_features(bs_df)
    except Exception as e:
        logging.critical(f"Feature Engineering Failed: {e}", exc_info=True)
        return

    # 2. DVP Merge
    if dvp_df is not None:
        logging.info("Merging Defense vs Position (DVP) stats...")
        if 'Pos' in bs_df.columns:
            bs_df['Primary_Pos'] = bs_df['Pos'].apply(normalize_position)
        else:
            bs_df['Primary_Pos'] = 'PG' 

        bs_df = pd.merge(
            bs_df, 
            dvp_df, 
            left_on=['OPPONENT_ABBREV', 'Primary_Pos'], 
            right_on=['OPPONENT_ABBREV', 'Primary_Pos'], 
            how='left'
        )
        dvp_cols = [c for c in dvp_df.columns if c.startswith('DVP_')]
        if dvp_cols:
            bs_df[dvp_cols] = bs_df[dvp_cols].fillna(bs_df[dvp_cols].mean())

    # 3. Team Stats Merge
    if team_stats_df is not None:
        logging.info("Merging Team Stats...")
        
        # FIX: Ensure TEAM_ABBREVIATION is a column, not index
        if 'TEAM_ABBREVIATION' not in team_stats_df.columns and team_stats_df.index.name == 'TEAM_ABBREVIATION':
            team_stats_df = team_stats_df.reset_index()
            
        # Prepare Team Stats (Prefix with TEAM_)
        # We assume any column NOT 'TEAM_ABBREVIATION' is a stat
        team_cols_map = {c: f"TEAM_{c}" for c in team_stats_df.columns if c != 'TEAM_ABBREVIATION'}
        team_df_clean = team_stats_df.rename(columns=team_cols_map)
        
        bs_df = pd.merge(bs_df, team_df_clean, on='TEAM_ABBREVIATION', how='left')
        
        # Prepare Opponent Stats (Prefix with OPP_)
        opp_cols_map = {c: f"OPP_{c}" for c in team_stats_df.columns if c != 'TEAM_ABBREVIATION'}
        opp_df_clean = team_stats_df.rename(columns=opp_cols_map)
        
        # Join Key: The opponent's abbreviation in the box score matches the Team Abbrev in the stats file
        opp_df_clean = opp_df_clean.rename(columns={'TEAM_ABBREVIATION': 'OPPONENT_ABBREV'})
        
        bs_df = pd.merge(bs_df, opp_df_clean, on='OPPONENT_ABBREV', how='left')

    # 4. Vacancy Features Check
    for col in ['MISSING_USG_G', 'MISSING_USG_F', 'TEAM_MISSING_USG', 'TEAM_MISSING_MIN']:
        if col not in bs_df.columns:
            bs_df[col] = 0.0
        else:
            bs_df[col] = bs_df[col].fillna(0.0)

    # 5. Final Cleanup
    bs_df = bs_df[bs_df['MIN'] > 0].copy()
    
    if output_path is None:
        output_path = cfg.DATA_DIR / "master_training_dataset.csv"
        
    bs_df.to_csv(output_path, index=False)
    logging.info(f"Saved master_training_dataset.csv with {len(bs_df)} rows and {len(bs_df.columns)} features.")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    create_training_dataset()