import pandas as pd
import numpy as np
import logging
from pathlib import Path
from prop_analyzer import config as cfg

def load_master_data():
    """
    Loads the cleaned master files generated by ETL.
    """
    try:
        box_scores = pd.read_csv(cfg.MASTER_BOX_SCORES_FILE, low_memory=False)
        
        # Load DVP Stats if available
        dvp_path = cfg.DATA_DIR / "master_dvp_stats.csv"
        if dvp_path.exists():
            dvp_df = pd.read_csv(dvp_path)
        else:
            dvp_df = None
            logging.warning("master_dvp_stats.csv not found. Skipping DVP merge.")

        # Load Team Stats
        if cfg.MASTER_TEAM_FILE.exists():
            team_stats = pd.read_csv(cfg.MASTER_TEAM_FILE)
        else:
            team_stats = None

        return box_scores, dvp_df, team_stats
    except Exception as e:
        logging.error(f"Failed to load master data: {e}")
        return None, None, None

def normalize_position(pos):
    """
    Standardizes position for DVP lookup.
    """
    if not isinstance(pos, str): return 'PG' # Default fallback
    p = pos.split('-')[0].upper().strip()
    if p == 'G': return 'SG'
    if p == 'F': return 'PF'
    if p not in ['PG', 'SG', 'SF', 'PF', 'C']: return 'PG'
    return p

def add_rolling_features(df):
    """
    Calculates historical features (SZN Avg, L5, Rest) for training.
    This ensures Training Data matches Inference Data structure.
    """
    logging.info("Calculating historical rolling features (this may take a moment)...")
    
    # Ensure sorted by date for rolling calculations
    df = df.sort_values(by=['PLAYER_ID', 'GAME_DATE']).reset_index(drop=True)
    
    # Features to engineer per-stat
    stats_to_roll = ['PTS', 'REB', 'AST', 'PRA', 'PR', 'PA', 'RA', 'FG3M', 'STL', 'BLK', 'TOV', 'FANTASY_PTS']
    # Ensure these cols exist (fill 0)
    for col in stats_to_roll:
        if col not in df.columns: df[col] = 0.0

    # Group by Player to prevent bleeding data between players
    grouped = df.groupby('PLAYER_ID')

    # 1. Days Rest
    # Create temporary helper column
    df['prev_date'] = grouped['GAME_DATE'].shift(1)
    df['Days Rest'] = (df['GAME_DATE'] - df['prev_date']).dt.days.fillna(7).clip(upper=7)
    
    # --- FIX: Drop datetime helper column immediately to prevent fillna errors ---
    df.drop(columns=['prev_date'], inplace=True)
    
    # 2. Rolling Stats (Shift 1 to prevent leakage - use PREVIOUS games to predict CURRENT)
    # We use .values to bypass pandas Index alignment errors (MultiIndex vs RangeIndex)
    
    for col in stats_to_roll:
        # SZN Avg (Expanding Mean)
        df[f'{col}_SZN_AVG'] = grouped[col].expanding().mean().shift(1).values
        
        # L5 Avg (Rolling 5)
        df[f'{col}_L5_AVG'] = grouped[col].rolling(window=5, min_periods=1).mean().shift(1).values
        
        # L3 Avg
        df[f'{col}_L3_AVG'] = grouped[col].rolling(window=3, min_periods=1).mean().shift(1).values
        
        # L10 Std Dev (Volatility)
        df[f'{col}_L10_STD'] = grouped[col].rolling(window=10, min_periods=3).std().shift(1).values
        
        # EWMA (Exponential) - mimics calculator.py decay
        # alpha=0.15 approx corresponds to decay 0.85
        df[f'{col}_L5_EWMA'] = grouped[col].ewm(alpha=0.15, adjust=False).mean().shift(1).values

    # 3. Advanced Stats Rolling
    if 'USG_PROXY' in df.columns:
        df['SZN_USG_PROXY'] = grouped['USG_PROXY'].expanding().mean().shift(1).values
        df['L5_USG_PROXY'] = grouped['USG_PROXY'].rolling(window=5).mean().shift(1).values
        
    if 'TS_PCT' in df.columns:
        df['SZN_TS_PCT'] = grouped['TS_PCT'].expanding().mean().shift(1).values
        df['L5_TS_PCT'] = grouped['TS_PCT'].rolling(window=5).mean().shift(1).values

    # 4. Game Count Context
    df['SZN Games'] = grouped.cumcount().values # 0, 1, 2...
    
    # 5. Cleanup NaNs created by shifting (First game of season has no history)
    # We fill with 0 or appropriate defaults. 
    # Since prev_date is gone, this is now safe.
    df.fillna(0, inplace=True)
    
    return df

def create_training_dataset(output_path=None):
    logging.info("--- Building Master Training Dataset ---")
    
    bs_df, dvp_df, team_stats_df = load_master_data()
    if bs_df is None or bs_df.empty:
        logging.critical("No box scores available. Aborting dataset creation.")
        return

    # 1. Base Filtering
    req_cols = ['PLAYER_ID', 'GAME_DATE', 'PTS', 'MIN', 'TEAM_ABBREVIATION', 'OPPONENT_ABBREV']
    if not all(c in bs_df.columns for c in req_cols):
        logging.error(f"Box scores missing required columns: {req_cols}")
        return

    bs_df['GAME_DATE'] = pd.to_datetime(bs_df['GAME_DATE'])
    bs_df.sort_values(by=['PLAYER_ID', 'GAME_DATE'], inplace=True)

    # --- NEW: Add Rolling History Features ---
    try:
        bs_df = add_rolling_features(bs_df)
    except Exception as e:
        logging.critical(f"Feature Engineering Failed: {e}", exc_info=True)
        return

    # 2. DVP Merge
    if dvp_df is not None:
        logging.info("Merging Defense vs Position (DVP) stats...")
        if 'Pos' in bs_df.columns:
            bs_df['Primary_Pos'] = bs_df['Pos'].apply(normalize_position)
        else:
            bs_df['Primary_Pos'] = 'PG' 

        bs_df = pd.merge(
            bs_df, 
            dvp_df, 
            left_on=['OPPONENT_ABBREV', 'Primary_Pos'], 
            right_on=['OPPONENT_ABBREV', 'Primary_Pos'], 
            how='left'
        )
        # Fill missing DVP
        dvp_cols = [c for c in dvp_df.columns if c.startswith('DVP_')]
        if dvp_cols:
            bs_df[dvp_cols] = bs_df[dvp_cols].fillna(bs_df[dvp_cols].mean())

    # 3. Team Stats Merge
    if team_stats_df is not None:
        logging.info("Merging Team Stats...")
        team_stats_df.columns = [f"TEAM_{c}" if c != 'TEAM_ABBREVIATION' else c for c in team_stats_df.columns]
        bs_df = pd.merge(bs_df, team_stats_df, on='TEAM_ABBREVIATION', how='left')
        
        opp_stats_df = pd.read_csv(cfg.MASTER_TEAM_FILE)
        opp_stats_df.columns = [f"OPP_{c}" if c != 'TEAM_ABBREVIATION' else 'OPPONENT_ABBREV' for c in opp_stats_df.columns]
        bs_df = pd.merge(bs_df, opp_stats_df, on='OPPONENT_ABBREV', how='left')

    # 4. Vacancy Features Check
    for col in ['MISSING_USG_G', 'MISSING_USG_F', 'TEAM_MISSING_USG', 'TEAM_MISSING_MIN']:
        if col not in bs_df.columns:
            bs_df[col] = 0.0
        else:
            bs_df[col] = bs_df[col].fillna(0.0)

    # 5. Final Cleanup
    bs_df = bs_df[bs_df['MIN'] > 0].copy()
    
    if output_path is None:
        output_path = cfg.DATA_DIR / "master_training_dataset.csv"
        
    bs_df.to_csv(output_path, index=False)
    logging.info(f"Saved master_training_dataset.csv with {len(bs_df)} rows and {len(bs_df.columns)} features.")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    create_training_dataset()